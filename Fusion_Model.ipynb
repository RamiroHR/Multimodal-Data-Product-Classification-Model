{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e257de",
   "metadata": {},
   "source": [
    "# Main workflow:\n",
    "* Modular implementation.  \n",
    "* High level programming (layer architecture).  \n",
    "* Import low level functions from a python script.  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "274c2c58",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##################################----This is pseudo code----##################################\n",
    "\n",
    "### define train test datasets\n",
    "raw_data = pd.read_csv(\"...\")\n",
    "raw_text_train, raw_text_test = split_raw_data(raw_data)\n",
    "\n",
    "### Initial steps: train model on text and model on image data separately.\n",
    "\n",
    "text = initialize_text_model()    ## return a NN\n",
    "text_data = get_text_data(raw_text_train)     ## return ready to train text data (from raw text to X_train, X_test text data)\n",
    "\n",
    "text.fit(text_data[\"train\"])    ## \n",
    "text.save(\"...\")\n",
    "\n",
    "\n",
    "image = initialize_image_model()\n",
    "image_data = get_image_data()\n",
    "\n",
    "image.fit(image_data[\"train\"])\n",
    "image.save(\"...\")\n",
    "\n",
    "\n",
    "\n",
    "### Train fusion model\n",
    "\n",
    "text_data = get_text_data()\n",
    "image_data = get_image_data()\n",
    "\n",
    "image_model = initialize_image_model()\n",
    "text_model = initialize_text_model()\n",
    "\n",
    "headless_image_model = remove_classification_head(image_model)\n",
    "headless_text_model = remove_classification_head(text_model)\n",
    "headless_text_model.save(\"...\")\n",
    "headless_image_model.save(\"...\")\n",
    "\n",
    "headless_X_train_image = headless_image_model.predict(image_data[\"train\"])\n",
    "headless_X_train_text = headless_text_model.predict(text_data[\"train\"])\n",
    "\n",
    "X_train = concatenate(headless_X_train_text, headless_X_train_image)\n",
    "\n",
    "fusion_model = build_fusion_model()\n",
    "fusion_model.fit(X_train)\n",
    "fusion_model.save(\"...\")\n",
    "# same with the test data\n",
    "\n",
    "\n",
    "### Prediction\n",
    "\n",
    "new_text_sample, new_image_sample = get_new_samples()\n",
    "\n",
    "hl_image_model = load_model(\"...\")\n",
    "hl_text_model = load_model(\"...\")\n",
    "\n",
    "sample = concatenate(hl_text_model.predict(new_text_sample), hl_image_model.predict(new_image_sample))\n",
    "fusion_model = load_model(\"...\")\n",
    "fusion_model.predict(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1392d4",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76b35d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import FusionModel_tools as fm\n",
    "import importlib\n",
    "importlib.reload(fm)\n",
    "\n",
    "import nltk\n",
    "nltk.download('popular', quiet = True)\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b36d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define general parameters\n",
    "\n",
    "myseed = 123\n",
    "\n",
    "splitting_path = '../Splitted_datasets/'\n",
    "preprocessing_path = '../Preprocessed_data/'\n",
    "training_path = '../Trained_models_and_metrics/'\n",
    "images_path = '../datasets/image_train/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f19ff0",
   "metadata": {},
   "source": [
    "# Initialize raw dataset\n",
    "* train test split\n",
    "* Split entire dataset once here to avoid any issues (information leak, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8fde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "## import raw datasets: features and target\n",
    "df_X = pd.read_csv('../datasets/X_train_update.csv', index_col = 0)\n",
    "df_y = pd.read_csv('../datasets/Y_train_CVw08PX.csv', index_col = 0).squeeze()  ## for correct splitting\n",
    "\n",
    "print(type(df_X), type(df_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6a89ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \n",
       "0                                                NaN  3804725264  1263597046  \n",
       "1                                                NaN   436067568  1008141237  \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978  \n",
       "3                                                NaN    50418756   457047496  \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            84906, 84907, 84908, 84909, 84910, 84911, 84912, 84913, 84914,\n",
      "            84915],\n",
      "           dtype='int64', length=84916)\n"
     ]
    }
   ],
   "source": [
    "display(df_X.head())\n",
    "print(df_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af810bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10\n",
       "1    2280\n",
       "2      50\n",
       "3    1280\n",
       "4    2705\n",
       "Name: prdtypecode, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            84906, 84907, 84908, 84909, 84910, 84911, 84912, 84913, 84914,\n",
      "            84915],\n",
      "           dtype='int64', length=84916)\n"
     ]
    }
   ],
   "source": [
    "display(df_y.head())\n",
    "print(df_y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8b939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: ../Splitted_datasets/2308141811_df_X_train.csv\n",
      "Saved dataset: ../Splitted_datasets/2308141811_df_X_test.csv\n",
      "Saved dataset: ../Splitted_datasets/2308141811_df_y_train.csv\n",
      "Saved dataset: ../Splitted_datasets/2308141811_df_y_test.csv\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "## train-test split raw data\n",
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_X, df_y, test_size = 0.2, \\\n",
    "                                                                random_state = myseed, stratify = df_y)\n",
    "\n",
    "## merge features and targets\n",
    "# df_train = pd.concat([df_y_train,df_X_train], axis = 1)\n",
    "# df_test = pd.concat([df_y_test,df_X_test], axis = 1)\n",
    "\n",
    "\n",
    "## save splitted dataframes\n",
    "fm.save(datasets = [df_X_train, df_X_test, df_y_train, df_y_test], \\\n",
    "             types = ['dataframe', 'dataframe', 'dataframe', 'dataframe'], \\\n",
    "             names = ['df_X_train', 'df_X_test', 'df_y_train', 'df_y_test'], \\\n",
    "              path = splitting_path, doit = True, verbose = True)\n",
    "\n",
    "\n",
    "## tranforms dataset to feed into the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a3304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 9263, 50884, 73788, 34901, 81204, 26065, 46256, 70161, 24947,\n",
       "            32350,\n",
       "            ...\n",
       "            29427,  6336, 69930, 71944, 18110, 19372, 79662, 38386, 84570,\n",
       "            60763],\n",
       "           dtype='int64', length=67932)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0271e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([76291, 35651, 23689, 27954, 53964, 25569,   462, 76121, 81032,\n",
       "            80184,\n",
       "            ...\n",
       "            43294, 23597, 28244,  7725, 20720, 84173, 53364, 62653, 33334,\n",
       "            83750],\n",
       "           dtype='int64', length=16984)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0b97e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "    From now on, the <b>test dataset</b> will only be used to asses the models performance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabaa78",
   "metadata": {},
   "source": [
    "# _Text data model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958492c",
   "metadata": {},
   "source": [
    "## Preprocess Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee47ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'designation' has been renamed as 'title' \n",
      "\n",
      "Columns 'title' and 'description' have been concatenated in a new variable 'title_descr' \n",
      "\n",
      "Column 'title_descr' has been successfully HTML parsed and decapitalized.\n",
      "\t HTML parsing takes 20.42 seconds \n",
      "\n",
      "Column 'title_descr' has been successfully tokenized.\n",
      "\t Tokenization + Lemmatization takes 27.33 seconds \n",
      "\n",
      "Main language detection takes 3.73 minutes.\n",
      "\t Language detection correction takes 3.17 seconds \n",
      "\n",
      "Removing stop-words takes 28.84 seconds. \n",
      "\n",
      "Token counting takes 0.03 seconds. \n",
      "\n",
      "Column 'designation' has been renamed as 'title' \n",
      "\n",
      "Columns 'title' and 'description' have been concatenated in a new variable 'title_descr' \n",
      "\n",
      "Column 'title_descr' has been successfully HTML parsed and decapitalized.\n",
      "\t HTML parsing takes 4.36 seconds \n",
      "\n",
      "Column 'title_descr' has been successfully tokenized.\n",
      "\t Tokenization + Lemmatization takes 5.30 seconds \n",
      "\n",
      "Main language detection takes 0.92 minutes.\n",
      "\t Language detection correction takes 2.22 seconds \n",
      "\n",
      "Removing stop-words takes 4.41 seconds. \n",
      "\n",
      "Token counting takes 0.01 seconds. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## preprocess datasets: Data cleaning & Feature engineering\n",
    "\n",
    "df_X_train_preprocess = fm.preprocess_text_data(df_X_train, verbose = True)\n",
    "df_X_test_preprocess = fm.preprocess_text_data(df_X_test, verbose = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df851632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: ../Preprocessed_data/2308141824_df_X_train_preprocess.csv\n",
      "Saved dataset: ../Preprocessed_data/2308141824_df_X_test_preprocess.csv\n"
     ]
    }
   ],
   "source": [
    "fm.save(datasets = [df_X_train_preprocess, df_X_test_preprocess], \\\n",
    "             types = ['dataframe', 'dataframe'],\n",
    "             names = ['df_X_train_preprocess', 'df_X_test_preprocess'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5f1b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 9263, 50884, 73788, 34901, 81204, 26065, 46256, 70161, 24947,\n",
       "            32350,\n",
       "            ...\n",
       "            29427,  6336, 69930, 71944, 18110, 19372, 79662, 38386, 84570,\n",
       "            60763],\n",
       "           dtype='int64', length=67932)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_preprocess.head()\n",
    "df_X_train_preprocess.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a735c",
   "metadata": {},
   "source": [
    "### Load preprocessed data\n",
    "Optional. It helps to free processing memory if restarting the kernel and loading the followinf datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f2c2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_preprocess = pd.read_csv(preprocessing_path+'2308121902_df_X_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_X_test_preprocess = pd.read_csv(preprocessing_path+'2308121902_df_X_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_train = pd.read_csv( splitting_path+'2308121827_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv( splitting_path+'2308121827_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "# df_X_train_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e284e19",
   "metadata": {},
   "source": [
    "## Data transformation & model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caadd871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67932, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_preprocess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f31e780c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer Vocabulary contains : 5000 terms\n",
      "First Vocabulary terms : {'lot': 2751, 'livres': 2731, 'merveilleux': 2896, 'violet': 4773, 'atterrissage': 632, 'prolongée': 3663, 'vitesse': 4785, 'appui': 541, 'protector': 3681, 'extension': 1907}\n"
     ]
    }
   ],
   "source": [
    "## transform dataset to feed into model\n",
    "\n",
    "text_data, targets, text_transformer, target_transformer = fm.get_text_data(df_X_train_preprocess, df_X_test_preprocess, df_y_train, df_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21fa70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sparseMatrix : ../Preprocessed_data/2308141825_text_data_transformed_X_train.npz\n",
      "Saved sparseMatrix : ../Preprocessed_data/2308141825_text_data_transformed_X_test.npz\n",
      "Saved dataset: ../Preprocessed_data/2308141825_text_data_transformed_y_train.npy\n",
      "Saved dataset: ../Preprocessed_data/2308141825_text_data_transformed_y_test.npy\n",
      "Saved transformer: ../Preprocessed_data/2308141825_token_len_scaler\n",
      "Saved transformer: ../Preprocessed_data/2308141825_language_encoder\n",
      "Saved transformer: ../Preprocessed_data/2308141825_lemmas_vectorizer\n",
      "Saved transformer: ../Preprocessed_data/2308141825_target_encoder\n"
     ]
    }
   ],
   "source": [
    "## Save transformed features:\n",
    "fm.save(datasets = [text_data['X_train'], text_data['X_test'] ], \\\n",
    "             types = ['sparseMatrix', 'sparseMatrix'], \\\n",
    "             names = ['text_data_transformed_X_train', 'text_data_transformed_X_test'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True )\n",
    "\n",
    "## save transformed targets:\n",
    "fm.save(datasets = [ targets['y_train'], targets['y_test'] ], \\\n",
    "             types = ['array', 'array'], \\\n",
    "             names = ['text_data_transformed_y_train', 'text_data_transformed_y_test'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True )\n",
    "\n",
    "## save tranformers:\n",
    "fm.save(datasets = [ text_transformer['token_len_scaler'], text_transformer['language_encoder'],\\\n",
    "                     text_transformer['lemmas_vectorizer'], target_transformer], \\\n",
    "             types = ['transformer', 'transformer','transformer', 'transformer'], \\\n",
    "             names = ['token_len_scaler','language_encoder', 'lemmas_vectorizer', 'target_encoder'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b7bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## intialize text model:\n",
    "\n",
    "text_model = fm.initialize_text_model(model_type  = \"NN\", \\\n",
    "                             Nb_features = text_data['X_train'].shape[1], \\\n",
    "                             Nb_classes  = targets['y_train'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5255e8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9263                    [lot, livres, contes, merveilleux]\n",
       "50884    [amiibo, splatoon, calamar, inkling, violet, n...\n",
       "73788    [atterrissage, prolongée, vitesse, jambe, appu...\n",
       "34901    [rideau, ameublement, chenille, 140, 260, saur...\n",
       "81204    [porte, carte, visites, magnetoplan, visite, t...\n",
       "                               ...                        \n",
       "19372    [chariot, marche, porteur, bois, hippopotame, ...\n",
       "79662                [carte, beyblade, série, gingka, 161]\n",
       "38386    [jouets, loisirs, pour, enfants, éducation, ne...\n",
       "84570    [broderie, peintures, strass, diamant, bricola...\n",
       "60763    [parure, housse, couette, coton, 140x200, fils...\n",
       "Name: lemma_tokens, Length: 67932, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_vectorize = 'lemma_tokens'\n",
    "df_X_train_preprocess[col_to_vectorize]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1227981",
   "metadata": {},
   "source": [
    "## Fit text model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3541a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8534 - accuracy: 0.4623 - val_loss: 1.9314 - val_accuracy: 0.4451\n",
      "Epoch 2/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8418 - accuracy: 0.4657 - val_loss: 1.9276 - val_accuracy: 0.4498\n",
      "Epoch 3/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8312 - accuracy: 0.4671 - val_loss: 1.9206 - val_accuracy: 0.4485\n",
      "Epoch 4/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8217 - accuracy: 0.4702 - val_loss: 1.9162 - val_accuracy: 0.4527\n",
      "Epoch 5/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8108 - accuracy: 0.4753 - val_loss: 1.9081 - val_accuracy: 0.4521\n",
      "Epoch 6/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8020 - accuracy: 0.4769 - val_loss: 1.9080 - val_accuracy: 0.4553\n",
      "Epoch 7/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7931 - accuracy: 0.4786 - val_loss: 1.8932 - val_accuracy: 0.4581\n",
      "Epoch 8/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7831 - accuracy: 0.4803 - val_loss: 1.8956 - val_accuracy: 0.4576\n",
      "Epoch 9/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7764 - accuracy: 0.4819 - val_loss: 1.8869 - val_accuracy: 0.4592\n",
      "Epoch 10/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7656 - accuracy: 0.4860 - val_loss: 1.8840 - val_accuracy: 0.4601\n",
      "Epoch 11/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7575 - accuracy: 0.4882 - val_loss: 1.8725 - val_accuracy: 0.4618\n",
      "Epoch 12/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7509 - accuracy: 0.4884 - val_loss: 1.8787 - val_accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7418 - accuracy: 0.4915 - val_loss: 1.8717 - val_accuracy: 0.4655\n",
      "Epoch 14/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7353 - accuracy: 0.4938 - val_loss: 1.8752 - val_accuracy: 0.4657\n",
      "Epoch 15/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7286 - accuracy: 0.4955 - val_loss: 1.8694 - val_accuracy: 0.4662\n",
      "Epoch 16/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7201 - accuracy: 0.4973 - val_loss: 1.8579 - val_accuracy: 0.4701\n",
      "Epoch 17/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7124 - accuracy: 0.4993 - val_loss: 1.8631 - val_accuracy: 0.4658\n",
      "Epoch 18/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7062 - accuracy: 0.5009 - val_loss: 1.8544 - val_accuracy: 0.4692\n",
      "Epoch 19/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.6990 - accuracy: 0.5031 - val_loss: 1.8527 - val_accuracy: 0.4720\n",
      "Epoch 20/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.6914 - accuracy: 0.5046 - val_loss: 1.8443 - val_accuracy: 0.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a13e29f310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model\n",
    "text_model.fit(text_data[\"X_train\"].toarray(), targets[\"y_train\"],\n",
    "               epochs = 5,\n",
    "              batch_size = 200,\n",
    "              validation_split = 0.2)    ## \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84241601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308102259_text_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained model:\n",
    "\n",
    "fm.save_model(text_model, name = 'text_model', \n",
    "              path = training_path, \n",
    "              doit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ea41b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308102259_text_model.keras\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,243\n",
      "Trainable params: 73,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## reload trained model:\n",
    "\n",
    "nn2 = fm.reload_model('2308102259_text_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddeb6e8f",
   "metadata": {},
   "source": [
    "# Image data\n",
    "\n",
    "* preprocess image data: crop, resize, vectorize\n",
    "* save prpprocessed image_dataset\n",
    "* transform image data: scale pixels, reshape for CNN\n",
    "* initialize model (using tranformed data dimensions)\n",
    "* save trained model\n",
    "* reload trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e8a140",
   "metadata": {},
   "source": [
    "## preprocess image data\n",
    "> * crop\n",
    "> * resize\n",
    "> * vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6feee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images at time 0.00 minutes\n",
      "1000 images at time 0.13 minutes\n",
      "2000 images at time 0.26 minutes\n",
      "3000 images at time 0.38 minutes\n",
      "4000 images at time 0.51 minutes\n",
      "5000 images at time 0.64 minutes\n",
      "10000 images at time 1.29 minutes\n",
      "15000 images at time 1.92 minutes\n",
      "20000 images at time 2.55 minutes\n",
      "25000 images at time 3.18 minutes\n",
      "30000 images at time 3.81 minutes\n",
      "35000 images at time 4.47 minutes\n",
      "40000 images at time 5.10 minutes\n",
      "45000 images at time 5.73 minutes\n",
      "50000 images at time 6.35 minutes\n",
      "55000 images at time 6.97 minutes\n",
      "60000 images at time 7.61 minutes\n",
      "65000 images at time 8.23 minutes\n",
      "Vectorization of 67932 images takes 8.61 minutes\n"
     ]
    }
   ],
   "source": [
    "# df_X_train_preprocess.head()\n",
    "# df_X_test_preprocess.head()\n",
    "\n",
    "\n",
    "# df_image_train_preprocess = fm.preprocess_image_data(df_X_train_preprocess, verbose = True)\n",
    "image_train_preprocess = fm.preprocess_image_data(df_X_train_preprocess, \n",
    "                                                     threshold = 230, \n",
    "                                                     new_pixel_nb = 100,\n",
    "                                                     path = images_path,                                                     \n",
    "                                                     output = 'array',\n",
    "                                                     verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7efb0ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images at time 0.00 minutes\n",
      "1000 images at time 0.13 minutes\n",
      "2000 images at time 0.26 minutes\n",
      "3000 images at time 0.38 minutes\n",
      "4000 images at time 0.50 minutes\n",
      "5000 images at time 0.63 minutes\n",
      "10000 images at time 1.26 minutes\n",
      "15000 images at time 1.89 minutes\n",
      "Vectorization of 16984 images takes 2.14 minutes\n"
     ]
    }
   ],
   "source": [
    "image_test_preprocess = fm.preprocess_image_data(df_X_test_preprocess, \n",
    "                                                     threshold = 230, \n",
    "                                                     new_pixel_nb = 100,\n",
    "                                                     path = images_path,\n",
    "                                                     output = 'array',\n",
    "                                                     verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bad78900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: ../Preprocessed_data/2308141850_df_image_train_preprocess.npy\n",
      "Saved dataset: ../Preprocessed_data/2308141850_df_image_test_preprocess.npy\n"
     ]
    }
   ],
   "source": [
    "fm.save(datasets = [df_image_train_preprocess, df_image_test_preprocess], \\\n",
    "            types = ['array', 'array'], \\\n",
    "             names = ['df_image_train_preprocess', 'df_image_test_preprocess'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e787dab",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "Optional. It helps to free processing memory if restarting the kernel and loading the followinf datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_image_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "# df_X_test_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_image_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "\n",
    "## reload saved numpy array for preprocessed image data\n",
    "import os\n",
    "\n",
    "image_train_preprocess = np.load(os.path.join(preprocessing_path, '2308141850_df_image_train_preprocess.npy'))\n",
    "image_test_preprocess = np.load(os.path.join(preprocessing_path, '2308141850_df_image_test_preprocess.npy'))\n",
    "\n",
    "\n",
    "## targets are in dataframes\n",
    "df_y_train = pd.read_csv(splitting_path + '2308141811_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv(splitting_path + '2308141811_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028c3c6",
   "metadata": {},
   "source": [
    "## Transform image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "747f9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fm.get_image_data(image_train_preprocess, image_test_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ff98b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.98431373 1.\n",
      " 0.18823529 0.19607843 0.22352941 0.17647059 0.15294118 0.14509804\n",
      " 0.16862745 0.18431373 0.17254902 0.15686275 0.18431373 0.21568627\n",
      " 0.22352941 0.21176471 0.21176471 0.17254902 0.24705882 0.23529412\n",
      " 0.19215686 0.17647059 0.21176471 0.22352941 0.19215686 0.21960784\n",
      " 0.20392157 0.2627451  0.23529412 0.23921569 0.23921569 0.23137255\n",
      " 0.28235294 0.30980392 0.33333333 0.28627451 0.28627451 0.28627451\n",
      " 0.25490196 0.23137255]\n"
     ]
    }
   ],
   "source": [
    "image_data.keys()\n",
    "type(image_data['train'])\n",
    "print(image_data['train'][0,0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3c46237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99607843\n",
      " 1.         0.98431373 0.85098039 0.79607843 0.80784314 0.80784314\n",
      " 0.80784314 0.80784314 0.80784314 0.80784314 0.80784314 0.80784314\n",
      " 0.80784314 0.80784314 0.80784314 0.80784314 0.80784314 0.80784314\n",
      " 0.80784314 0.80392157 0.80392157 0.80392157 0.80784314 0.80392157\n",
      " 0.8        0.79607843]\n"
     ]
    }
   ],
   "source": [
    "print(image_data['test'][0,0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23d52b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved compressed large array: ../Preprocessed_data/2308141953_image_train_transformed.npz\n",
      "Saved compressed large array: ../Preprocessed_data/2308141953_image_test_transformed.npz\n"
     ]
    }
   ],
   "source": [
    "## THIS takes about 5 - 7 minutes\n",
    "\n",
    "fm.save(datasets = [ image_data['train'], image_data['test'] ], \\\n",
    "            types = ['arrayXL', 'arrayXL'], \\\n",
    "             names = ['image_train_transformed', 'image_test_transformed'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24df2b7",
   "metadata": {},
   "source": [
    "## initialize image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0f23ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## intialize image model:\n",
    "\n",
    "image_model = fm.initialize_image_model(model_type  = \"CNN\", \\\n",
    "                             image_shape = image_data['train'].shape[1:], \\\n",
    "                             Nb_classes  = targets['y_train'].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c42a51b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694680d0",
   "metadata": {},
   "source": [
    "## Fit text model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "883d2f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "272/272 [==============================] - 138s 501ms/step - loss: 2.7128 - accuracy: 0.2699 - val_loss: 2.3050 - val_accuracy: 0.3538\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 123s 452ms/step - loss: 2.0930 - accuracy: 0.4044 - val_loss: 2.2083 - val_accuracy: 0.3774\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 121s 444ms/step - loss: 1.7354 - accuracy: 0.4977 - val_loss: 2.1891 - val_accuracy: 0.4027\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 122s 449ms/step - loss: 1.3769 - accuracy: 0.5961 - val_loss: 2.2296 - val_accuracy: 0.4016\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 120s 440ms/step - loss: 1.0495 - accuracy: 0.6935 - val_loss: 2.4051 - val_accuracy: 0.4155\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 119s 438ms/step - loss: 0.7937 - accuracy: 0.7697 - val_loss: 2.6589 - val_accuracy: 0.4133\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 120s 442ms/step - loss: 0.6135 - accuracy: 0.8238 - val_loss: 2.8579 - val_accuracy: 0.4075\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 120s 443ms/step - loss: 0.4860 - accuracy: 0.8638 - val_loss: 3.1999 - val_accuracy: 0.3980\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 120s 440ms/step - loss: 0.4009 - accuracy: 0.8889 - val_loss: 3.3228 - val_accuracy: 0.3967\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 122s 448ms/step - loss: 0.3316 - accuracy: 0.9103 - val_loss: 3.6083 - val_accuracy: 0.3996\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "training_history = image_model.fit(image_data[\"train\"], text_data[\"y_train\"],\n",
    "                             validation_split = 0.2,\n",
    "                             epochs = 10,\n",
    "                             batch_size = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9534a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308111738\n"
     ]
    }
   ],
   "source": [
    "model_date_time = fm.date_time()\n",
    "print(model_date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7144380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308111739_image_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained model:\n",
    "\n",
    "fm.save_model(image_model, name = 'image_model', \n",
    "              path = training_path, \n",
    "              doit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7cf5a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308111739_image_model.keras\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## reload trained model:\n",
    "\n",
    "cnn2 = fm.reload_model('2308111739_image_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cbcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "383179e6",
   "metadata": {},
   "source": [
    "# Fusion model\n",
    "\n",
    "**Get training data ready to feed**  \n",
    "text_data = get_text_data()  \n",
    "image_data = get_image_data()  \n",
    "\n",
    "**Define headless models**  \n",
    "image_model = initialize_image_model()  \n",
    "text_model = initialize_text_model()  \n",
    "\n",
    "headless_image_model = remove_classification_head(image_model)  \n",
    "headless_text_model = remove_classification_head(text_model)  \n",
    "headless_text_model.save(\"...\")  \n",
    "headless_image_model.save(\"...\")  \n",
    "\n",
    "**define train data for fusion model**  \n",
    "headless_X_train_image = headless_image_model.predict(image_data[\"train\"])  \n",
    "headless_X_train_text = headless_text_model.predict(text_data[\"train\"])  \n",
    "\n",
    "X_train = concatenate(headless_X_train_text, headless_X_train_image)  \n",
    "\n",
    "**define and train fusion model**  \n",
    "fusion_model = build_fusion_model()  \n",
    "fusion_model.fit(X_train)  \n",
    "fusion_model.save(\"...\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3163fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bf1b865",
   "metadata": {},
   "source": [
    "**Get text and image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7abca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload preprocessed data\n",
    "\n",
    "df_X_train_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_X_test_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_train = pd.read_csv('./Preprocessed_data/2308102203_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv('./Preprocessed_data/2308102203_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "# df_X_train_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935c5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get text data\n",
    "## transform dataset to feed into model\n",
    "\n",
    "text_data, targets, text_transformer, target_transformer = fm.get_text_data(df_X_train_preprocess, df_X_test_preprocess, df_y_train, df_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5d9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload preprocessed image data\n",
    "image_train_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_train_preprocess.npy'))\n",
    "image_test_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_test_preprocess.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b46c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get image data\n",
    "image_data = fm.get_image_data(image_train_preprocess, image_test_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5af527",
   "metadata": {},
   "source": [
    "**define headless models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07901794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308102259_text_model.keras\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,243\n",
      "Trainable params: 73,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load text pretrained model:  parent model\n",
    "\n",
    "text_model = fm.reload_model('2308102259_text_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be30448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,392\n",
      "Trainable params: 59,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## define the headless_model for text\n",
    "\n",
    "headless_text_model = fm.remove_classification_head(text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110ab605",
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify that is actually works:\n",
    "\n",
    "# headless_text_model.summary()\n",
    "# headless_text_model.predict(text_data['X_test'].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356649b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875673dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308111739_image_model.keras\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load image pretrained model:\n",
    "\n",
    "image_model = fm.reload_model('2308111739_image_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26dc08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,439,744\n",
      "Trainable params: 9,439,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## define headless model for image data:\n",
    "\n",
    "headless_image_model = fm.remove_classification_head(image_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a21bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify that is actually works:\n",
    "\n",
    "# headless_text_model.summary()\n",
    "# headless_image_model.predict(image_data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3118b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2740abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model saved as ./Trained_models_and_metrics/2308111859_headless_text_model.keras\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model saved as ./Trained_models_and_metrics/2308111859_headless_image_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save both headless models:\n",
    "\n",
    "fm.save_model(headless_text_model, name = 'headless_text_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n",
    "\n",
    "fm.save_model(headless_image_model, name = 'headless_image_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536f0ff",
   "metadata": {},
   "source": [
    "**define train data for fusion model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef193f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123/2123 [==============================] - 3s 1ms/step\n",
      "2123/2123 [==============================] - 57s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "headless_X_train_text = headless_text_model.predict(text_data['X_train'].toarray())\n",
    "headless_X_train_image = headless_image_model.predict(image_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce4acef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: 2308111913_concatenated_headless_X_train.npy\n"
     ]
    }
   ],
   "source": [
    "## concatenate both datasets\n",
    "X_train = np.hstack((headless_X_train_text,headless_X_train_image))\n",
    "\n",
    "## save concatenated array\n",
    "fm.save(datasets = [X_train], \\\n",
    "            types = ['array'], \\\n",
    "             names = ['concatenated_headless_X_train'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58566f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67932, 640)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e6ac9",
   "metadata": {},
   "source": [
    "**define and train fusion model**  \n",
    "- fusion_model = build_fusion_model()  \n",
    "- fusion_model.fit(X_train)  \n",
    "- fusion_model.save(\"...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75af55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 640)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               82048     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,531\n",
      "Trainable params: 85,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_NN = {'Nb_features' : X_train.shape[1],\n",
    "             'Nb_classes'  : targets['y_train'].shape[1]}\n",
    "\n",
    "fusion_model = fm.initialize_fusion_model('NN', params = params_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daae6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67932, 27)\n"
     ]
    }
   ],
   "source": [
    "### I don't need to freeze the model since the other layer are not being trained\n",
    "print(targets['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "519d56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123/2123 [==============================] - 5s 2ms/step - loss: 0.8017 - accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a2d033af0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_model.fit(X_train, targets['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43d3d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308111936_fusion_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained fusion model\n",
    "\n",
    "fm.save_model(fusion_model, name = 'fusion_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa36a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
