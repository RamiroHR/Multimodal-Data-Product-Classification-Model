{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e257de",
   "metadata": {},
   "source": [
    "# Main workflow:\n",
    "* Modular implementation.  \n",
    "* High level programming (layer architecture).  \n",
    "* Import low level functions from a python script.  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "274c2c58",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##################################----This is pseudo code----##################################\n",
    "\n",
    "### define train test datasets\n",
    "raw_data = pd.read_csv(\"...\")\n",
    "raw_text_train, raw_text_test = split_raw_data(raw_data)\n",
    "\n",
    "### Initial steps: train model on text and model on image data separately.\n",
    "\n",
    "text = initialize_text_model()    ## return a NN\n",
    "text_data = get_text_data(raw_text_train)     ## return ready to train text data (from raw text to X_train, X_test text data)\n",
    "\n",
    "text.fit(text_data[\"train\"])    ## \n",
    "text.save(\"...\")\n",
    "\n",
    "\n",
    "image = initialize_image_model()\n",
    "image_data = get_image_data()\n",
    "\n",
    "image.fit(image_data[\"train\"])\n",
    "image.save(\"...\")\n",
    "\n",
    "\n",
    "\n",
    "### Train fusion model\n",
    "\n",
    "text_data = get_text_data()\n",
    "image_data = get_image_data()\n",
    "\n",
    "image_model = initialize_image_model()\n",
    "text_model = initialize_text_model()\n",
    "\n",
    "headless_image_model = remove_classification_head(image_model)\n",
    "headless_text_model = remove_classification_head(text_model)\n",
    "headless_text_model.save(\"...\")\n",
    "headless_image_model.save(\"...\")\n",
    "\n",
    "headless_X_train_image = headless_image_model.predict(image_data[\"train\"])\n",
    "headless_X_train_text = headless_text_model.predict(text_data[\"train\"])\n",
    "\n",
    "X_train = concatenate(headless_X_train_text, headless_X_train_image)\n",
    "\n",
    "fusion_model = build_fusion_model()\n",
    "fusion_model.fit(X_train)\n",
    "fusion_model.save(\"...\")\n",
    "# same with the test data\n",
    "\n",
    "\n",
    "### Prediction\n",
    "\n",
    "new_text_sample, new_image_sample = get_new_samples()\n",
    "\n",
    "hl_image_model = load_model(\"...\")\n",
    "hl_text_model = load_model(\"...\")\n",
    "\n",
    "sample = concatenate(hl_text_model.predict(new_text_sample), hl_image_model.predict(new_image_sample))\n",
    "fusion_model = load_model(\"...\")\n",
    "fusion_model.predict(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1392d4",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b35d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import FusionModel_tools as fm\n",
    "import importlib\n",
    "importlib.reload(fm)\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define general parameters\n",
    "\n",
    "myseed = 123\n",
    "\n",
    "splitting_path = './Splitted_datasets/'\n",
    "preprocessing_path = './Preprocessed_data/'\n",
    "training_path = './Trained_models_and_metrics/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f19ff0",
   "metadata": {},
   "source": [
    "# Initialize raw dataset\n",
    "* train test split\n",
    "* Split entire dataset once here to avoid any issues (information leak, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff8b939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: 2308102203_df_X_train.csv\n",
      "Saved dataset: 2308102203_df_X_test.csv\n",
      "Saved dataset: 2308102203_df_y_train.csv\n",
      "Saved dataset: 2308102203_df_y_test.csv\n"
     ]
    }
   ],
   "source": [
    "## import raw datasets: features and target\n",
    "df_X = pd.read_csv('./datasets/X_train_update.csv', index_col = 0)\n",
    "df_y = pd.read_csv('./datasets/Y_train_CVw08PX.csv', index_col = 0)\n",
    "\n",
    "\n",
    "## train-test split raw data\n",
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_X, df_y, test_size = 0.2, \\\n",
    "                                                                random_state = myseed, stratify = df_y)\n",
    "\n",
    "## merge features and targets\n",
    "# df_train = pd.concat([df_y_train,df_X_train], axis = 1)\n",
    "# df_test = pd.concat([df_y_test,df_X_test], axis = 1)\n",
    "\n",
    "\n",
    "## save splitted dataframes\n",
    "fm.save(dataframes = [df_X_train, df_X_test, df_y_train, df_y_test], \\\n",
    "             types = ['dataframe', 'dataframe', 'dataframe', 'dataframe'], \\\n",
    "             names = ['df_X_train', 'df_X_test', 'df_y_train', 'df_y_test'], \\\n",
    "              path = splitting_path, doit = True, verbose = True)\n",
    "\n",
    "\n",
    "## tranforms dataset to feed into the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0b97e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "    From now on, the <b>test dataset</b> will only be used to asses the models performance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabaa78",
   "metadata": {},
   "source": [
    "# _Text data model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958492c",
   "metadata": {},
   "source": [
    "## Preprocess Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bee47ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'designation' has been renamed as 'title' \n",
      "\n",
      "Columns 'title' and 'description' have been concatenated in a new variable 'title_descr' \n",
      "\n",
      "Column 'title_descr' has been successfully HTML parsed and decapitalized.\n",
      "\t HTML parsing takes 17.68 seconds \n",
      "\n",
      "Column 'title_descr' has been successfully tokenized.\n",
      "\t Tokenization + Lemmatization takes 21.58 seconds \n",
      "\n",
      "Main language detection takes 3.74 minutes.\n",
      "\t Language detection correction takes 2.88 seconds \n",
      "\n",
      "Removing stop-words takes 17.43 seconds. \n",
      "\n",
      "Token counting takes 0.03 seconds. \n",
      "\n",
      "Column 'designation' has been renamed as 'title' \n",
      "\n",
      "Columns 'title' and 'description' have been concatenated in a new variable 'title_descr' \n",
      "\n",
      "Column 'title_descr' has been successfully HTML parsed and decapitalized.\n",
      "\t HTML parsing takes 4.24 seconds \n",
      "\n",
      "Column 'title_descr' has been successfully tokenized.\n",
      "\t Tokenization + Lemmatization takes 5.41 seconds \n",
      "\n",
      "Main language detection takes 0.97 minutes.\n",
      "\t Language detection correction takes 2.03 seconds \n",
      "\n",
      "Removing stop-words takes 4.47 seconds. \n",
      "\n",
      "Token counting takes 0.01 seconds. \n",
      "\n",
      "Saved dataset: 2308102210_df_X_train_preprocess.csv\n",
      "Saved dataset: 2308102210_df_X_test_preprocess.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## preprocess datasets: Data cleaning & Feature engineering\n",
    "\n",
    "df_X_train_preprocess = fm.preprocess_text_data(df_X_train, verbose = True)\n",
    "df_X_test_preprocess = fm.preprocess_text_data(df_X_test, verbose = True)\n",
    "\n",
    "fm.save(dataframes = [df_X_train_preprocess, df_X_test_preprocess], \\\n",
    "             types = ['dataframe', 'dataframe'],\n",
    "             names = ['df_X_train_preprocess', 'df_X_test_preprocess'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f5f1b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>title_descr</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>text_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35666</th>\n",
       "      <td>Spa 5 places Calios - Spalnéa - Acrylique Blan...</td>\n",
       "      <td>Dimensions : 215 x 185 x 93 cm //// Nombre et ...</td>\n",
       "      <td>1926714940</td>\n",
       "      <td>1113061652</td>\n",
       "      <td>spa 5 places calios - spalnéa - acrylique blan...</td>\n",
       "      <td>[spa, place, calios, spalnéa, acrylique, blanc...</td>\n",
       "      <td>fr</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19651</th>\n",
       "      <td>New Flame Coupe Humidifier Night Light Mute Bu...</td>\n",
       "      <td>New Flame Coupe Humidifier Night Light Mute Bu...</td>\n",
       "      <td>4220470182</td>\n",
       "      <td>1319055786</td>\n",
       "      <td>new flame coupe humidifier night light mute bu...</td>\n",
       "      <td>[new, flame, coupe, humidifier, night, light, ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50216</th>\n",
       "      <td>Voice Control Calendar Thermometer Wooden Led ...</td>\n",
       "      <td>Voice ControlCalendar Thermometer Wooden LED D...</td>\n",
       "      <td>4079113221</td>\n",
       "      <td>1287738265</td>\n",
       "      <td>voice control calendar thermometer wooden led ...</td>\n",
       "      <td>[voice, control, calendar, thermometer, wooden...</td>\n",
       "      <td>en</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32733</th>\n",
       "      <td>Enrouleur Télescopique A. PRO \"NEW LINE\" Modèl...</td>\n",
       "      <td>Utilisation de l'Enrouleur Télescopique A. PRO...</td>\n",
       "      <td>228489648</td>\n",
       "      <td>958568141</td>\n",
       "      <td>enrouleur télescopique a. pro \"new line\" modèl...</td>\n",
       "      <td>[enrouleur, télescopique, pro, new, line, modè...</td>\n",
       "      <td>fr</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67840</th>\n",
       "      <td>Chaise De Bureau Inclinable Cuir Artificiel Rouge</td>\n",
       "      <td>&lt;p&gt;Cette luxueuse chaise de bureau inclinable ...</td>\n",
       "      <td>3929324475</td>\n",
       "      <td>1265058699</td>\n",
       "      <td>chaise de bureau inclinable cuir artificiel ro...</td>\n",
       "      <td>[chaise, bureau, inclinable, cuir, artificiel,...</td>\n",
       "      <td>fr</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "35666  Spa 5 places Calios - Spalnéa - Acrylique Blan...   \n",
       "19651  New Flame Coupe Humidifier Night Light Mute Bu...   \n",
       "50216  Voice Control Calendar Thermometer Wooden Led ...   \n",
       "32733  Enrouleur Télescopique A. PRO \"NEW LINE\" Modèl...   \n",
       "67840  Chaise De Bureau Inclinable Cuir Artificiel Rouge   \n",
       "\n",
       "                                             description   productid  \\\n",
       "35666  Dimensions : 215 x 185 x 93 cm //// Nombre et ...  1926714940   \n",
       "19651  New Flame Coupe Humidifier Night Light Mute Bu...  4220470182   \n",
       "50216  Voice ControlCalendar Thermometer Wooden LED D...  4079113221   \n",
       "32733  Utilisation de l'Enrouleur Télescopique A. PRO...   228489648   \n",
       "67840  <p>Cette luxueuse chaise de bureau inclinable ...  3929324475   \n",
       "\n",
       "          imageid                                        title_descr  \\\n",
       "35666  1113061652  spa 5 places calios - spalnéa - acrylique blan...   \n",
       "19651  1319055786  new flame coupe humidifier night light mute bu...   \n",
       "50216  1287738265  voice control calendar thermometer wooden led ...   \n",
       "32733   958568141  enrouleur télescopique a. pro \"new line\" modèl...   \n",
       "67840  1265058699  chaise de bureau inclinable cuir artificiel ro...   \n",
       "\n",
       "                                            lemma_tokens language  \\\n",
       "35666  [spa, place, calios, spalnéa, acrylique, blanc...       fr   \n",
       "19651  [new, flame, coupe, humidifier, night, light, ...       fr   \n",
       "50216  [voice, control, calendar, thermometer, wooden...       en   \n",
       "32733  [enrouleur, télescopique, pro, new, line, modè...       fr   \n",
       "67840  [chaise, bureau, inclinable, cuir, artificiel,...       fr   \n",
       "\n",
       "       text_token_len  \n",
       "35666             130  \n",
       "19651             112  \n",
       "50216              88  \n",
       "32733              48  \n",
       "67840             101  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a735c",
   "metadata": {},
   "source": [
    "### Load preprocessed data\n",
    "Optional. It helps to free processing memory if restarting the kernel and loading the followinf datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2c2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_X_test_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_train = pd.read_csv('./Preprocessed_data/2308102203_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv('./Preprocessed_data/2308102203_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "# df_X_train_preprocess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e284e19",
   "metadata": {},
   "source": [
    "## Data transformation & model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31e780c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## transform dataset to feed into model\n",
    "\n",
    "text_data, targets, text_transformer, target_transformer = fm.get_text_data(df_X_train_preprocess, df_X_test_preprocess, df_y_train, df_y_test)\n",
    "\n",
    "\n",
    "## intialize text model:\n",
    "\n",
    "text_model = fm.initialize_text_model(model_type  = \"NN\", \\\n",
    "                             Nb_features = text_data['X_train'].shape[1], \\\n",
    "                             Nb_classes  = targets['y_train'].shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1227981",
   "metadata": {},
   "source": [
    "## Fit text model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3541a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8534 - accuracy: 0.4623 - val_loss: 1.9314 - val_accuracy: 0.4451\n",
      "Epoch 2/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8418 - accuracy: 0.4657 - val_loss: 1.9276 - val_accuracy: 0.4498\n",
      "Epoch 3/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8312 - accuracy: 0.4671 - val_loss: 1.9206 - val_accuracy: 0.4485\n",
      "Epoch 4/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8217 - accuracy: 0.4702 - val_loss: 1.9162 - val_accuracy: 0.4527\n",
      "Epoch 5/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8108 - accuracy: 0.4753 - val_loss: 1.9081 - val_accuracy: 0.4521\n",
      "Epoch 6/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.8020 - accuracy: 0.4769 - val_loss: 1.9080 - val_accuracy: 0.4553\n",
      "Epoch 7/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7931 - accuracy: 0.4786 - val_loss: 1.8932 - val_accuracy: 0.4581\n",
      "Epoch 8/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7831 - accuracy: 0.4803 - val_loss: 1.8956 - val_accuracy: 0.4576\n",
      "Epoch 9/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7764 - accuracy: 0.4819 - val_loss: 1.8869 - val_accuracy: 0.4592\n",
      "Epoch 10/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7656 - accuracy: 0.4860 - val_loss: 1.8840 - val_accuracy: 0.4601\n",
      "Epoch 11/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7575 - accuracy: 0.4882 - val_loss: 1.8725 - val_accuracy: 0.4618\n",
      "Epoch 12/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7509 - accuracy: 0.4884 - val_loss: 1.8787 - val_accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7418 - accuracy: 0.4915 - val_loss: 1.8717 - val_accuracy: 0.4655\n",
      "Epoch 14/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7353 - accuracy: 0.4938 - val_loss: 1.8752 - val_accuracy: 0.4657\n",
      "Epoch 15/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7286 - accuracy: 0.4955 - val_loss: 1.8694 - val_accuracy: 0.4662\n",
      "Epoch 16/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7201 - accuracy: 0.4973 - val_loss: 1.8579 - val_accuracy: 0.4701\n",
      "Epoch 17/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7124 - accuracy: 0.4993 - val_loss: 1.8631 - val_accuracy: 0.4658\n",
      "Epoch 18/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.7062 - accuracy: 0.5009 - val_loss: 1.8544 - val_accuracy: 0.4692\n",
      "Epoch 19/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.6990 - accuracy: 0.5031 - val_loss: 1.8527 - val_accuracy: 0.4720\n",
      "Epoch 20/20\n",
      "272/272 [==============================] - 1s 3ms/step - loss: 1.6914 - accuracy: 0.5046 - val_loss: 1.8443 - val_accuracy: 0.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a13e29f310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train model\n",
    "text_model.fit(text_data[\"X_train\"].toarray(), targets[\"y_train\"],\n",
    "               epochs = 20,\n",
    "              batch_size = 200,\n",
    "              validation_split = 0.2)    ## \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84241601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308102259_text_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained model:\n",
    "\n",
    "fm.save_model(text_model, name = 'text_model', \n",
    "              path = training_path, \n",
    "              doit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ea41b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308102259_text_model.keras\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,243\n",
      "Trainable params: 73,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## reload trained model:\n",
    "\n",
    "nn2 = fm.reload_model('2308102259_text_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddeb6e8f",
   "metadata": {},
   "source": [
    "# Image data\n",
    "\n",
    "* preprocess image data: crop, resize, vectorize\n",
    "* save prpprocessed image_dataset\n",
    "* transform image data: scale pixels, reshape for CNN\n",
    "* initialize model (using tranformed data dimensions)\n",
    "* save trained model\n",
    "* reload trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e8a140",
   "metadata": {},
   "source": [
    "## preprocess image data\n",
    "> * crop\n",
    "> * resize\n",
    "> * vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6feee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images at time 0.00 minutes\n",
      "1000 images at time 0.13 minutes\n",
      "2000 images at time 0.25 minutes\n",
      "3000 images at time 0.38 minutes\n",
      "4000 images at time 0.50 minutes\n",
      "5000 images at time 0.63 minutes\n",
      "10000 images at time 1.25 minutes\n",
      "15000 images at time 1.87 minutes\n",
      "20000 images at time 2.49 minutes\n",
      "25000 images at time 3.12 minutes\n",
      "30000 images at time 3.74 minutes\n",
      "35000 images at time 4.36 minutes\n",
      "40000 images at time 4.99 minutes\n",
      "45000 images at time 5.61 minutes\n",
      "50000 images at time 6.24 minutes\n",
      "55000 images at time 6.87 minutes\n",
      "60000 images at time 7.49 minutes\n",
      "65000 images at time 8.11 minutes\n",
      "Vectorization of 67932 images takes 8.48 minutes\n"
     ]
    }
   ],
   "source": [
    "# df_X_train_preprocess.head()\n",
    "# df_X_test_preprocess.head()\n",
    "\n",
    "\n",
    "# df_image_train_preprocess = fm.preprocess_image_data(df_X_train_preprocess, verbose = True)\n",
    "df_image_train_preprocess = fm.preprocess_image_data(df_X_train_preprocess, \n",
    "                                                     threshold = 230, \n",
    "                                                     new_pixel_nb = 100,\n",
    "                                                     output = 'array',\n",
    "                                                     verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7efb0ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images at time 0.00 minutes\n",
      "1000 images at time 0.13 minutes\n",
      "2000 images at time 0.25 minutes\n",
      "3000 images at time 0.37 minutes\n",
      "4000 images at time 0.50 minutes\n",
      "5000 images at time 0.63 minutes\n",
      "10000 images at time 1.25 minutes\n",
      "15000 images at time 1.89 minutes\n",
      "Vectorization of 16984 images takes 2.14 minutes\n"
     ]
    }
   ],
   "source": [
    "df_image_test_preprocess = fm.preprocess_image_data(df_X_test_preprocess, \n",
    "                                                     threshold = 230, \n",
    "                                                     new_pixel_nb = 100, \n",
    "                                                     output = 'array',\n",
    "                                                     verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bad78900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: 2308111631_df_image_train_preprocess.npy\n",
      "Saved dataset: 2308111631_df_image_test_preprocess.npy\n"
     ]
    }
   ],
   "source": [
    "fm.save(datasets = [df_image_train_preprocess, df_image_test_preprocess], \\\n",
    "            types = ['array', 'array'], \\\n",
    "             names = ['df_image_train_preprocess', 'df_image_test_preprocess'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c86e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e787dab",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "Optional. It helps to free processing memory if restarting the kernel and loading the followinf datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_image_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "# df_X_test_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_image_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "\n",
    "## reload saved numpy array for preprocessed image data\n",
    "import os\n",
    "\n",
    "image_train_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_train_preprocess.npy'))\n",
    "image_test_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_test_preprocess.npy'))\n",
    "\n",
    "\n",
    "## targets are in dataframes\n",
    "df_y_train = pd.read_csv('./Preprocessed_data/2308102203_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv('./Preprocessed_data/2308102203_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028c3c6",
   "metadata": {},
   "source": [
    "## Transform image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "747f9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fm.get_image_data(image_train_preprocess, image_test_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ff98b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24df2b7",
   "metadata": {},
   "source": [
    "## initialize image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0f23ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## intialize image model:\n",
    "\n",
    "image_model = fm.initialize_image_model(model_type  = \"CNN\", \\\n",
    "                             image_shape = image_data['train'].shape[1:], \\\n",
    "                             Nb_classes  = targets['y_train'].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c42a51b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694680d0",
   "metadata": {},
   "source": [
    "## Fit text model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "883d2f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "272/272 [==============================] - 138s 501ms/step - loss: 2.7128 - accuracy: 0.2699 - val_loss: 2.3050 - val_accuracy: 0.3538\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 123s 452ms/step - loss: 2.0930 - accuracy: 0.4044 - val_loss: 2.2083 - val_accuracy: 0.3774\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 121s 444ms/step - loss: 1.7354 - accuracy: 0.4977 - val_loss: 2.1891 - val_accuracy: 0.4027\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 122s 449ms/step - loss: 1.3769 - accuracy: 0.5961 - val_loss: 2.2296 - val_accuracy: 0.4016\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 120s 440ms/step - loss: 1.0495 - accuracy: 0.6935 - val_loss: 2.4051 - val_accuracy: 0.4155\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 119s 438ms/step - loss: 0.7937 - accuracy: 0.7697 - val_loss: 2.6589 - val_accuracy: 0.4133\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 120s 442ms/step - loss: 0.6135 - accuracy: 0.8238 - val_loss: 2.8579 - val_accuracy: 0.4075\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 120s 443ms/step - loss: 0.4860 - accuracy: 0.8638 - val_loss: 3.1999 - val_accuracy: 0.3980\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 120s 440ms/step - loss: 0.4009 - accuracy: 0.8889 - val_loss: 3.3228 - val_accuracy: 0.3967\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 122s 448ms/step - loss: 0.3316 - accuracy: 0.9103 - val_loss: 3.6083 - val_accuracy: 0.3996\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "training_history = image_model.fit(image_data[\"train\"], text_data[\"y_train\"],\n",
    "                             validation_split = 0.2,\n",
    "                             epochs = 10,\n",
    "                             batch_size = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9534a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308111738\n"
     ]
    }
   ],
   "source": [
    "model_date_time = fm.date_time()\n",
    "print(model_date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7144380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308111739_image_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained model:\n",
    "\n",
    "fm.save_model(image_model, name = 'image_model', \n",
    "              path = training_path, \n",
    "              doit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7cf5a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308111739_image_model.keras\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## reload trained model:\n",
    "\n",
    "cnn2 = fm.reload_model('2308111739_image_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cbcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "383179e6",
   "metadata": {},
   "source": [
    "# Fusion model\n",
    "\n",
    "**Get training data ready to feed**  \n",
    "text_data = get_text_data()  \n",
    "image_data = get_image_data()  \n",
    "\n",
    "**Define headless models**  \n",
    "image_model = initialize_image_model()  \n",
    "text_model = initialize_text_model()  \n",
    "\n",
    "headless_image_model = remove_classification_head(image_model)  \n",
    "headless_text_model = remove_classification_head(text_model)  \n",
    "headless_text_model.save(\"...\")  \n",
    "headless_image_model.save(\"...\")  \n",
    "\n",
    "**define train data for fusion model**  \n",
    "headless_X_train_image = headless_image_model.predict(image_data[\"train\"])  \n",
    "headless_X_train_text = headless_text_model.predict(text_data[\"train\"])  \n",
    "\n",
    "X_train = concatenate(headless_X_train_text, headless_X_train_image)  \n",
    "\n",
    "**define and train fusion model**  \n",
    "fusion_model = build_fusion_model()  \n",
    "fusion_model.fit(X_train)  \n",
    "fusion_model.save(\"...\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3163fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bf1b865",
   "metadata": {},
   "source": [
    "**Get text and image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7abca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload preprocessed data\n",
    "\n",
    "df_X_train_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_train_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_X_test_preprocess = pd.read_csv('./Preprocessed_data/2308102210_df_X_test_preprocess.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_train = pd.read_csv('./Preprocessed_data/2308102203_df_y_train.csv', header = 0, index_col = 0, sep = ',')\n",
    "df_y_test = pd.read_csv('./Preprocessed_data/2308102203_df_y_test.csv', header = 0, index_col = 0, sep = ',')\n",
    "\n",
    "# df_X_train_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935c5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get text data\n",
    "## transform dataset to feed into model\n",
    "\n",
    "text_data, targets, text_transformer, target_transformer = fm.get_text_data(df_X_train_preprocess, df_X_test_preprocess, df_y_train, df_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5d9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload preprocessed image data\n",
    "image_train_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_train_preprocess.npy'))\n",
    "image_test_preprocess = np.load(os.path.join(preprocessing_path, '2308111631_df_image_test_preprocess.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b46c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get image data\n",
    "image_data = fm.get_image_data(image_train_preprocess, image_test_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5af527",
   "metadata": {},
   "source": [
    "**define headless models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07901794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308102259_text_model.keras\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,243\n",
      "Trainable params: 73,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load text pretrained model:  parent model\n",
    "\n",
    "text_model = fm.reload_model('2308102259_text_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be30448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 115)]             0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 512)               59392     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,392\n",
      "Trainable params: 59,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## define the headless_model for text\n",
    "\n",
    "headless_text_model = fm.remove_classification_head(text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110ab605",
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify that is actually works:\n",
    "\n",
    "# headless_text_model.summary()\n",
    "# headless_text_model.predict(text_data['X_test'].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356649b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875673dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model from ./Trained_models_and_metrics/2308111739_image_model.keras\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,443,227\n",
      "Trainable params: 9,443,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load image pretrained model:\n",
    "\n",
    "image_model = fm.reload_model('2308111739_image_model.keras', \n",
    "                       path = training_path, \n",
    "                       doit = True)\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26dc08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               9437312   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,439,744\n",
      "Trainable params: 9,439,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## define headless model for image data:\n",
    "\n",
    "headless_image_model = fm.remove_classification_head(image_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a21bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify that is actually works:\n",
    "\n",
    "# headless_text_model.summary()\n",
    "# headless_image_model.predict(image_data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3118b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2740abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model saved as ./Trained_models_and_metrics/2308111859_headless_text_model.keras\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model saved as ./Trained_models_and_metrics/2308111859_headless_image_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save both headless models:\n",
    "\n",
    "fm.save_model(headless_text_model, name = 'headless_text_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n",
    "\n",
    "fm.save_model(headless_image_model, name = 'headless_image_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536f0ff",
   "metadata": {},
   "source": [
    "**define train data for fusion model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef193f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123/2123 [==============================] - 3s 1ms/step\n",
      "2123/2123 [==============================] - 57s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "headless_X_train_text = headless_text_model.predict(text_data['X_train'].toarray())\n",
    "headless_X_train_image = headless_image_model.predict(image_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce4acef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset: 2308111913_concatenated_headless_X_train.npy\n"
     ]
    }
   ],
   "source": [
    "## concatenate both datasets\n",
    "X_train = np.hstack((headless_X_train_text,headless_X_train_image))\n",
    "\n",
    "## save concatenated array\n",
    "fm.save(datasets = [X_train], \\\n",
    "            types = ['array'], \\\n",
    "             names = ['concatenated_headless_X_train'], \\\n",
    "              path = preprocessing_path, doit = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58566f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67932, 640)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e6ac9",
   "metadata": {},
   "source": [
    "**define and train fusion model**  \n",
    "- fusion_model = build_fusion_model()  \n",
    "- fusion_model.fit(X_train)  \n",
    "- fusion_model.save(\"...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75af55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 640)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               82048     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,531\n",
      "Trainable params: 85,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_NN = {'Nb_features' : X_train.shape[1],\n",
    "             'Nb_classes'  : targets['y_train'].shape[1]}\n",
    "\n",
    "fusion_model = fm.initialize_fusion_model('NN', params = params_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daae6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67932, 27)\n"
     ]
    }
   ],
   "source": [
    "### I don't need to freeze the model since the other layer are not being trained\n",
    "print(targets['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "519d56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123/2123 [==============================] - 5s 2ms/step - loss: 0.8017 - accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a2d033af0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_model.fit(X_train, targets['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43d3d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./Trained_models_and_metrics/2308111936_fusion_model.keras\n"
     ]
    }
   ],
   "source": [
    "## save trained fusion model\n",
    "\n",
    "fm.save_model(fusion_model, name = 'fusion_model', \n",
    "              path = training_path, \n",
    "              doit = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa36a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
